# Architecture Flow Analysis

## âœ… **ARCHITECTURE vs CODE COMPARISON**

### **Expected Flow (from architecture.png):**

```
1. INITIAL DATA (CSV) â†’ Spark SQL â†’ Cassandra
2. INITIAL DATA (CSV) â†’ MODEL (Random Forest)
3. Kafka â†’ Spark Streaming â†’ Spark MLlib (uses MODEL) â†’ Cassandra
4. Cassandra â†’ Dashboard (Flask) â†’ FRAUD ALERT
```

---

### **Actual Code Flow:**

#### **1. Data Import (`spark_data_import.py`)**
```55:78:src/spark_data_import.py
    train_df = spark.read.csv("dataset/fraudTrain.csv", header=True, inferSchema=True)
    test_df = spark.read.csv("dataset/fraudTest.csv", header=True, inferSchema=True)
```
- âœ… **Source**: CSV files (`dataset/fraudTrain.csv`, `dataset/fraudTest.csv`)
- âœ… **Processing**: Spark SQL (ETL, feature engineering)
- âœ… **Destination**: Cassandra (`fraud_transaction`, `non_fraud_transaction`, `customer` tables)
- âœ… **Matches Architecture**: INITIAL DATA â†’ Spark SQL â†’ Cassandra

---

#### **2. ML Training (`spark_ml_training.py`)**
```55:75:src/spark_ml_training.py
    train_df = (
        spark.read.csv(
            "dataset/fraudTrain.csv",
            header=True,
            inferSchema=True,
            enforceSchema=False
        )
        .drop("_c0")
    )

    test_df = (
        spark.read.csv(
            "dataset/fraudTest.csv",
            header=True,
            inferSchema=True,
            enforceSchema=False
        )
        .drop("_c0")
    )

    df = train_df.union(test_df)
```
- âœ… **Source**: CSV files (`dataset/fraudTrain.csv`, `dataset/fraudTest.csv`) - **NOT Cassandra!**
- âœ… **Processing**: Spark MLlib (Random Forest Classifier)
- âœ… **Output**: Saved model to `models/spark_fraud_model`
- âœ… **Matches Architecture**: INITIAL DATA â†’ MODEL

---

#### **3. Real-time Detection (`spark_streaming_detector.py`)**
```112:120:src/spark_streaming_detector.py
    # Load trained Spark ML model
    print("\n[2/5] Loading Spark ML model...")
    try:
        model = PipelineModel.load("models/spark_fraud_model")
        print("âœ“ Spark ML model loaded (Random Forest)")
        use_ml_model = True
    except Exception as e:
        print(f"âš  Model not found, using is_fraud label directly: {e}")
        use_ml_model = False
```
```127:133:src/spark_streaming_detector.py
    kafka_df = (spark.readStream
        .format("kafka")
        .option("kafka.bootstrap.servers", KAFKA_BROKER)
        .option("subscribe", KAFKA_TOPIC)
        .option("startingOffsets", "earliest")
        .option("failOnDataLoss", "false")
        .load())
```
```196:202:src/spark_streaming_detector.py
                try:
                    fraud_alerts.write \
                        .format("org.apache.spark.sql.cassandra") \
                        .options(table="fraud_alert", keyspace="creditcard") \
                        .mode("append") \
                        .save()
                    print(f"  âœ“ Saved {fraud_count} alerts to Cassandra")
```
- âœ… **Source**: Kafka (`creditcardTransaction` topic)
- âœ… **Processing**: Spark Streaming â†’ Spark MLlib (loads trained model)
- âœ… **Destination**: Cassandra (`fraud_alert` table)
- âœ… **Matches Architecture**: Kafka â†’ Spark Streaming â†’ Spark MLlib â†’ Cassandra

---

#### **4. Dashboard (`dashboard.py`)**
```86:107:src/dashboard.py
@app.route('/api/recent_fraud')
def get_recent_fraud():
    session = get_cassandra_session()

    # Recent frauds (LIMIT 20)
    rows = session.execute("""
        SELECT cc_num, trans_time, merchant, amt, category
        FROM fraud_transaction
        LIMIT 20
    """)

    fraud_list = []
    for row in rows:
        fraud_list.append({
            "cc_num": row.cc_num[-4:] if row.cc_num else "****",
            "time": row.trans_time.strftime('%Y-%m-%d %H:%M:%S') if row.trans_time else "",
            "merchant": row.merchant,
            "amount": float(row.amt),
            "category": row.category
        })

    return jsonify(fraud_list)
```
- âœ… **Source**: Cassandra (`fraud_transaction`, `fraud_alert` tables)
- âœ… **Processing**: Flask + SocketIO (real-time updates)
- âœ… **Output**: Web dashboard with fraud alerts
- âœ… **Matches Architecture**: Cassandra â†’ Dashboard â†’ FRAUD ALERT

---

## ğŸ¯ **ANSWER TO YOUR QUESTIONS:**

### **Q1: Is the architecture and our code the same?**
**âœ… YES!** The code flow exactly matches the architecture diagram:
- âœ… CSV â†’ Spark SQL â†’ Cassandra
- âœ… CSV â†’ ML Training â†’ Model
- âœ… Kafka â†’ Spark Streaming â†’ ML Model â†’ Cassandra
- âœ… Cassandra â†’ Dashboard â†’ Alerts

---

### **Q2: Is ML using Cassandra or initial data?**
**âœ… ML Training uses INITIAL DATA (CSV files), NOT Cassandra!**

**Evidence:**
- `spark_ml_training.py` reads directly from `dataset/fraudTrain.csv` and `dataset/fraudTest.csv`
- It does **NOT** read from Cassandra tables
- This matches the architecture diagram which shows: **INITIAL DATA â†’ MODEL**

**Why?**
- Training needs the full historical dataset with labels
- Cassandra is used for:
  - Storing processed transactions (for dashboard queries)
  - Storing real-time fraud alerts (from streaming)
  - **NOT** for ML training data

---

## ğŸ“Š **COMPLETE DATA FLOW:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CSV Files      â”‚
â”‚  (Initial Data) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                 â”‚
         â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ spark_data_     â”‚  â”‚ spark_ml_       â”‚
â”‚ import.py       â”‚  â”‚ training.py     â”‚
â”‚ (Spark SQL)     â”‚  â”‚ (Spark MLlib)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                    â”‚
         â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Cassandra     â”‚  â”‚  ML Model       â”‚
â”‚   (Storage)     â”‚  â”‚  (Random Forest)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                    â”‚
         â”‚                    â”‚
         â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚         â”‚                     â”‚
         â”‚         â–¼                     â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
         â”‚  â”‚  Kafka         â”‚          â”‚
         â”‚  â”‚  (Real-time)   â”‚          â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
         â”‚           â”‚                  â”‚
         â”‚           â–¼                  â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
         â”‚  â”‚ spark_streaming_â”‚         â”‚
         â”‚  â”‚ detector.py     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚  â”‚ (Spark Streamingâ”‚
         â”‚  â”‚  + ML Model)    â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚           â”‚
         â”‚           â–¼
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  â”‚   Cassandra     â”‚
         â”‚  â”‚  (fraud_alert)  â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚           â”‚
         â”‚           â–¼
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  â”‚   Dashboard     â”‚
         â”‚  â”‚   (Flask)       â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… **CONCLUSION:**

**Everything matches the architecture!** The code correctly:
1. Uses CSV files for initial data import and ML training
2. Uses Cassandra for storing processed data and real-time alerts
3. Uses Kafka for real-time transaction streaming
4. Uses Spark (SQL, MLlib, Streaming) for all Big Data processing
5. Uses Flask dashboard for visualization

**No changes needed!** ğŸ‰

